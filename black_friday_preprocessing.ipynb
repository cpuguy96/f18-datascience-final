{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Modelling Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_p_cats(df):\n",
    "    temp = df\n",
    "    for p_cat in ['p_cat_1', 'p_cat_2', 'p_cat_3']:\n",
    "        ranges = pd.unique(pd.Series(temp[p_cat]))\n",
    "        ranges.sort()\n",
    "        mapped = ['p_cat_' + str(x) for x in ranges]\n",
    "        temp['p_cat'] = temp[p_cat].map(dict(zip(ranges, mapped)))\n",
    "        one_hot = pd.get_dummies(temp['p_cat'])\n",
    "        temp = temp.drop(p_cat, axis = 1)\n",
    "        one_hot = one_hot.replace(0, np.nan)\n",
    "        temp = temp.combine_first(one_hot)\n",
    "    temp = temp.fillna(0)\n",
    "    temp = temp.drop(['p_cat', 'p_cat_0'], axis = 1)\n",
    "\n",
    "    p_cols = ['p_cat_1', 'p_cat_10', 'p_cat_11', 'p_cat_12', 'p_cat_13', 'p_cat_14',\n",
    "   'p_cat_15', 'p_cat_16', 'p_cat_17', 'p_cat_18', 'p_cat_2', 'p_cat_3',\n",
    "   'p_cat_4', 'p_cat_5', 'p_cat_6', 'p_cat_7', 'p_cat_8', 'p_cat_9']\n",
    "\n",
    "    temp[p_cols] = temp[p_cols].astype(int)\n",
    "    temp[p_cols] = temp[p_cols].astype(int)\n",
    "    return temp\n",
    "\n",
    "def write_model_dataset(chosen, combine_cats = False):\n",
    "    raw_df = pd.read_csv(\"inputs/BlackFriday.csv\")\n",
    "    modeldf = raw_df.rename(columns =   {'User_ID' : 'u_id',\n",
    "                                'Product_ID' : 'p_id',\n",
    "                                'Gender' : 'gender',\n",
    "                                'Age' : 'age',\n",
    "                                'Occupation' : 'occ',\n",
    "                                'City_Category' : 'city',\n",
    "                                'Stay_In_Current_City_Years' : 'years_in_city',\n",
    "                                'Marital_Status' : 'married',\n",
    "                                'Product_Category_1' : 'p_cat_1',\n",
    "                                'Product_Category_2' : 'p_cat_2',\n",
    "                                'Product_Category_3' : 'p_cat_3',\n",
    "                                'Purchase' : 'pur'})\n",
    "    file_name = \"\"\n",
    "    cols = np.asarray(modeldf.columns)\n",
    "    \n",
    "    # normalize user_id and prod_id, impute 0 into NaN p_cat\n",
    "    modeldf['u_id'] = modeldf['u_id'] - 1000000\n",
    "    modeldf['p_id'] = modeldf['p_id'].replace('[A-Za-z]', '', regex = True)\n",
    "    modeldf['p_id'] = pd.to_numeric(modeldf.p_id, errors='coerce')\n",
    "    modeldf['p_cat_2'].fillna(0, inplace = True)\n",
    "    modeldf['p_cat_3'].fillna(0, inplace = True)\n",
    "    modeldf['p_cat_2'] = modeldf['p_cat_2'].astype(int)\n",
    "    modeldf['p_cat_3'] = modeldf['p_cat_3'].astype(int)\n",
    "    \n",
    "    # Creates dataset with imputed 0s and labelvector on age\n",
    "    if chosen == 0:\n",
    "        # uncomment these 2 lines to replace 0's with mean\n",
    "        #modeldf['p_cat_2'].replace(0, modeldf['p_cat_2'].mean(), inplace = True)\n",
    "        #modeldf['p_cat_3'].replace(0, modeldf['p_cat_3'].mean(), inplace = True)\n",
    "        label_features = ['gender', 'age', 'years_in_city', 'city']\n",
    "        for feature in label_features:\n",
    "            ranges = pd.unique(pd.Series(modeldf[feature]))\n",
    "            ranges.sort()\n",
    "            mapped = [x for x in range(len(ranges))]\n",
    "            modeldf[feature] = modeldf[feature].map(dict(zip(ranges, mapped)))\n",
    "        file_name = \"minimal_preprocess.csv\"\n",
    "    elif chosen == 1:\n",
    "        # Creates dataset with one hot vectors on occ, city, p_cats\n",
    "        \n",
    "        one_hot_features = []\n",
    "        if combine_cats:\n",
    "            one_hot_features = ['occ', 'city']\n",
    "        else:\n",
    "            one_hot_features = ['occ', 'city', 'p_cat_1', 'p_cat_2', 'p_cat_3']\n",
    "        \n",
    "        for feature in one_hot_features:\n",
    "            if feature in cols:\n",
    "                ranges = pd.unique(pd.Series(modeldf[feature]))\n",
    "                ranges.sort()\n",
    "                mapped = [feature + '_' + str(x) for x in ranges]\n",
    "                modeldf[feature] = modeldf[feature].map(dict(zip(ranges, mapped)))\n",
    "                one_hot = pd.get_dummies(modeldf[feature])\n",
    "                modeldf = modeldf.drop(feature, axis = 1)\n",
    "                modeldf = modeldf.join(one_hot) \n",
    "\n",
    "        if combine_cats:\n",
    "            modeldf = combine_p_cats(modeldf)\n",
    "        \n",
    "        label_features = ['gender', 'age', 'years_in_city']\n",
    "\n",
    "        for feature in label_features:\n",
    "            ranges = pd.unique(pd.Series(modeldf[feature]))\n",
    "            ranges.sort()\n",
    "            mapped = [x for x in range(len(ranges))]\n",
    "            modeldf[feature] = modeldf[feature].map(dict(zip(ranges, mapped)))\n",
    "        file_name = \"some_one_hot.csv\"\n",
    "        \n",
    "    elif chosen == 2:\n",
    "        # creates dataset with one hot vectors on all categorical features\n",
    "        cat_features = []\n",
    "        if combine_cats:\n",
    "            cat_features = ['age', 'occ', 'city', 'years_in_city']\n",
    "        else:\n",
    "            cat_features = ['age', 'occ', 'city', 'years_in_city', 'p_cat_1', 'p_cat_2', 'p_cat_3']\n",
    "            \n",
    "        for cat in cat_features:\n",
    "            if cat in cols:\n",
    "                ranges = pd.unique(pd.Series(modeldf[cat]))\n",
    "                ranges.sort()\n",
    "                mapped = [cat + '_' + str(x) for x in range(len(ranges))]\n",
    "                modeldf[cat] = modeldf[cat].map(dict(zip(ranges, mapped)))\n",
    "                one_hot = pd.get_dummies(modeldf[cat])\n",
    "                modeldf = modeldf.drop(cat, axis = 1)\n",
    "                modeldf = modeldf.join(one_hot)\n",
    "        \n",
    "        if combine_cats:\n",
    "            modeldf = combine_p_cats(modeldf)\n",
    "        \n",
    "        label_features = ['gender']\n",
    "\n",
    "        for feature in label_features:\n",
    "            ranges = pd.unique(pd.Series(modeldf[feature]))\n",
    "            ranges.sort()\n",
    "            mapped = [str(x) for x in range(len(ranges))]\n",
    "            modeldf[feature] = modeldf[feature].map(dict(zip(ranges, mapped)))\n",
    "        file_name = \"all_one_hot.csv\"\n",
    "    if len(file_name) != 0:  \n",
    "        if chosen != 0 and combine_cats == True:\n",
    "            modeldf.to_csv(\"inputs/p_combined_\" + file_name , encoding='utf-8', index = False)\n",
    "        else:\n",
    "            modeldf.to_csv(\"inputs/\" + file_name , encoding='utf-8', index = False)\n",
    "    \n",
    "        \n",
    "    return modeldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimal_preprocess = 0\n",
    "# some_one_hot = 1\n",
    "# all_one_hot = 2\n",
    "# True = combine product categories\n",
    "\n",
    "write_model_dataset(2, True).head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
