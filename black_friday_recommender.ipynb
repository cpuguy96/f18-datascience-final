{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from zipfile import ZipFile\n",
    "import warnings\n",
    "import xgboost as xgb\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split_predictions():\n",
    "    count = 0\n",
    "    with ZipFile('outputs/xgb_models_and_data.zip', 'r') as zipfile:\n",
    "        count = len(zipfile.infolist())\n",
    "        zipfile.extractall()\n",
    "    print(\"Found buffer zip file\")\n",
    "    print(\"Number of files\", count)\n",
    "    #predictions = \n",
    "    user_clusterdf = pd.read_csv(\"outputs/user_multi_cluster_assignments.csv\")\n",
    "    purdf = user_clusterdf.iloc[0:0]\n",
    "    predictions = 0\n",
    "    count = int(count/2)\n",
    "    for i in range(count):\n",
    "        segment = user_clusterdf[user_clusterdf['cluster_num'] == i]\n",
    "        bst = xgb.Booster({'nthread': 4})  # init model\n",
    "        bst.load_model('outputs/xgb_model%d.bin' % i) # load model\n",
    "        dmodel = xgb.DMatrix('outputs/xgb_data%d.buffer' % i) # load model data\n",
    "        segment['pur_pred'] = bst.predict(dmodel)\n",
    "        if i == 0:\n",
    "            purdf = segment\n",
    "        else:\n",
    "            purdf = pd.concat([purdf, segment])\n",
    "    user_clusterdf['colFromIndex'] = user_clusterdf.index\n",
    "    user_clusterdf = user_clusterdf.sort_values(['cluster_num', 'colFromIndex'])\n",
    "    user_clusterdf = user_clusterdf.join(purdf['pur_pred']).sort_values(['colFromIndex'])\n",
    "    return user_clusterdf['pur_pred'].values\n",
    "    \n",
    "def get_predictions():\n",
    "    with ZipFile('outputs/xgb_model_and_data.zip', 'r') as zipfile:\n",
    "        zipfile.extractall()\n",
    "    print(\"Found buffer zip file\")\n",
    "    bst = xgb.Booster({'nthread': 4})  # init model\n",
    "    bst.load_model('outputs/xgb_model.bin') # load model\n",
    "    dmodel = xgb.DMatrix('outputs/xgb_data.buffer')# load model data\n",
    "    return bst.predict(dmodel)\n",
    "    \n",
    "def create_cluster_pred_pur(split_models = False):\n",
    "    predictions = []\n",
    "    user_clusterdf = []\n",
    "    if split_models:\n",
    "        try:\n",
    "            predictions = get_split_predictions()\n",
    "            user_clusterdf = pd.read_csv(\"outputs/user_multi_cluster_assignments.csv\")\n",
    "        except:\n",
    "            print(\"Failed to find models and data zip file.\")\n",
    "            return 0\n",
    "    else:\n",
    "        try:\n",
    "            predictions = get_predictions()\n",
    "            user_clusterdf = pd.read_csv(\"outputs/user_cluster_assignments.csv\")\n",
    "        except:\n",
    "            print(\"Failed to find model and data zip file.\")\n",
    "            return 0\n",
    "    \n",
    "    user_pred_clusterdf = user_clusterdf.join(pd.DataFrame(data = predictions, columns = ['pur_pred']))\n",
    "\n",
    "    unique_clusters = user_pred_clusterdf['cluster_num'].unique()\n",
    "    unique_clusters.sort()\n",
    "\n",
    "    for cluster_num in unique_clusters:\n",
    "        cluster = user_pred_clusterdf[user_pred_clusterdf['cluster_num'] == cluster_num]\n",
    "\n",
    "        p_cats = ['p_cat_1', 'p_cat_2', 'p_cat_3']\n",
    "        prod_cats = cluster['p_cat_1'].unique()\n",
    "        prod_cats.sort()\n",
    "        pur_sums = {x:0 for x in prod_cats}\n",
    "\n",
    "        for cat in p_cats:\n",
    "            prod_cats = cluster[cat].unique()\n",
    "            prod_cats = prod_cats[prod_cats != 0]\n",
    "            prod_cats.sort()\n",
    "            for prod_cat in prod_cats:\n",
    "                pur_sums[prod_cat] += cluster[cluster[cat] == prod_cat]['pur_pred'].sum()\n",
    "\n",
    "        cluster_pur = pd.DataFrame(list(pur_sums.items()), columns = ['p_cat', 'total_pur_pred'])\n",
    "        if split_models:\n",
    "            cluster_pur.to_csv(\"outputs/split_cluster_%d_pred_pur.csv\" % cluster_num, encoding='utf-8', index = False)\n",
    "        else:\n",
    "            cluster_pur.to_csv(\"outputs/cluster_%d_pred_pur.csv\" % cluster_num, encoding='utf-8', index = False)\n",
    "        print(\"Wrote Cluster\", cluster_num, \"Predicted Purchase Information\")\n",
    "    return len(unique_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading top k product categories for each cluster\n",
    "def top_k_cats(top_k = 18):\n",
    "    top_k = min(max(top_k, 0), 18)\n",
    "    for x in range(num_clusters):\n",
    "        cluster_pur = pd.read_csv(\"outputs/cluster_%d_pred_pur.csv\" % x)\n",
    "        top_k_cats = cluster_pur.nlargest(top_k, 'total_pur_pred')['p_cat'].values\n",
    "        print(\"Top %d product categories for cluster %d: %s\" % (top_k, x, \" \".join(str(cat) for cat in top_k_cats)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendations from Combined Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found buffer zip file\n",
      "[07:28:30] 537577x69 matrix with 37092813 entries loaded from outputs/xgb_data.buffer\n",
      "Wrote Cluster 0 Predicted Purchase Information\n",
      "Wrote Cluster 1 Predicted Purchase Information\n",
      "Wrote Cluster 2 Predicted Purchase Information\n"
     ]
    }
   ],
   "source": [
    "num_clusters = create_cluster_pred_pur()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 product categories for cluster 0: 1 8 5 2 16 15 14 6 17 4\n",
      "Top 10 product categories for cluster 1: 1 8 5 16 2 15 14 6 17 4\n",
      "Top 10 product categories for cluster 2: 1 8 5 16 2 15 14 6 4 17\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "top_k_cats(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recomendations from Split Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found buffer zip file\n",
      "Number of files 6\n",
      "[07:28:36] 24790x80 matrix with 1983200 entries loaded from outputs/xgb_data0.buffer\n",
      "[07:28:36] 215832x80 matrix with 17266560 entries loaded from outputs/xgb_data1.buffer\n",
      "[07:28:37] 296955x80 matrix with 23756400 entries loaded from outputs/xgb_data2.buffer\n",
      "Wrote Cluster 0 Predicted Purchase Information\n",
      "Wrote Cluster 1 Predicted Purchase Information\n",
      "Wrote Cluster 2 Predicted Purchase Information\n"
     ]
    }
   ],
   "source": [
    "num_clusters = create_cluster_pred_pur(split_models = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 product categories for cluster 0: 1 8 5 2 16 15 14 6 17 4\n",
      "Top 10 product categories for cluster 1: 1 8 5 16 2 15 14 6 17 4\n",
      "Top 10 product categories for cluster 2: 1 8 5 16 2 15 14 6 4 17\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "top_k_cats(k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
